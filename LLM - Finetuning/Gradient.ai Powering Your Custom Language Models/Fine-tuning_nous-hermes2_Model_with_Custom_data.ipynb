{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_e6CTeeHcdoZ",
    "outputId": "bc437439-3d05-4411-fd19-ce51d48a6e18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gradientai\n",
      "  Downloading gradientai-1.13.1-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting aenum>=3.1.11 (from gradientai)\n",
      "  Downloading aenum-3.1.15-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.10.15 in /usr/local/lib/python3.10/dist-packages (from gradientai) (2.8.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from gradientai) (2.8.2)\n",
      "Requirement already satisfied: urllib3>=1.25.3 in /usr/local/lib/python3.10/dist-packages (from gradientai) (2.0.7)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.10.15->gradientai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.10.15->gradientai) (2.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.10.15->gradientai) (4.12.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->gradientai) (1.16.0)\n",
      "Downloading gradientai-1.13.1-py3-none-any.whl (410 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.7/410.7 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aenum-3.1.15-py3-none-any.whl (137 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.6/137.6 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: aenum, gradientai\n",
      "Successfully installed aenum-3.1.15 gradientai-1.13.1\n"
     ]
    }
   ],
   "source": [
    "!pip install gradientai --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "SU3cUwwacjww"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['GRADIENT_WORKSPACE_ID']='Past Your Work Space Here'\n",
    "os.environ['GRADIENT_ACCESS_TOKEN']='Past Your Access Token Here'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Install Gradient.ai Library** : The !pip install gradientai --upgrade command installs the gradientai library, which provides the Python interface for interacting with the Gradient.ai platform.  \n",
    "- **Set Environment Variables** : You're using environment variables to store your Gradient.ai workspace ID and access token. This is a secure way to handle sensitive information.  \n",
    "- **Import Gradient Class** : The from gradientai import Gradient line imports the Gradient class, which you'll use to create a connection to your Gradient.ai workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0U5D6rx6deHY",
    "outputId": "06ba50e8-2ec7-4b2e-8ca7-12be64621c66"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created model adapter with id cde35519-a8c0-47e8-9bd3-f7221533e481_model_adapter\n",
      "Asking: ### Instruction: What is NLP and LLM? \n",
      "\n",
      " ### Response:\n",
      "Generated(before fine tuning):  NLP stands for Natural Language Processing, which is a field of artificial intelligence (AI) that focuses on the interaction between computers and humans using natural language. It involves the use of algorithms and computational models to process, analyze, and understand human language.\n",
      "\n",
      "LLM, on the other hand, stands for Language Modeling. It is a specific subfield of NLP that focuses on creating models that can predict the probability of a sequence of words in a given language. LLM\n",
      "Fine tuning the model with iteration 1\n",
      "Fine tuning the model with iteration 2\n",
      "Fine tuning the model with iteration 3\n",
      "Fine tuning the model with iteration 4\n",
      "Fine tuning the model with iteration 5\n",
      "Fine tuning the model with iteration 6\n",
      "Generated(after fine tuning):  NLP stands for Natural Language Processing. It's a field of AI that helps computers understand and process human language. LLM stands for Large Language Model. It's a type of AI model trained on massive amounts of text data, allowing it to generate human-like text, translate languages, write different kinds of creative content, and answer your questions in an informative way.\n"
     ]
    }
   ],
   "source": [
    "from gradientai import Gradient\n",
    "\n",
    "# ** 1. Main Function ( main()) **\n",
    "def main():\n",
    "    gradient = Gradient()    #creates an instance of the Gradient class, initiating a connection to your Gradient.ai workspace using the environment variables set earlier.\n",
    "   \n",
    "\n",
    "   # ** 2. Load Base Model. **\n",
    "    base_model = gradient.get_base_model(base_model_slug=\"nous-hermes2\")\n",
    "        # using gradient.get_base_model() to retrieve a pre-trained language model from Gradient.ai. \n",
    "        # The base_model_slug=\"nous-hermes2\" specifies that you're working with the \"Nous Hermes 2\" model.\n",
    "        ## **What is Nous Hermes 2?** This model is a large language model from Gradient.ai. \n",
    "                              # It's likely specialized for tasks like text generation, question answering, and maybe even some form of code generation.\n",
    "   \n",
    "\n",
    "    # ** 3. Create Model Adapter ** \n",
    "    new_model_adapter = base_model.create_model_adapter(\n",
    "        name=\"Krishna_model\"\n",
    "    )\n",
    "    print(f\"Created model adapter with id {new_model_adapter.id}\")\n",
    "         # Create Model Adapter: This line creates a \"model adapter\" using the base model. The adapter is essentially a customized instance of the base model that you can fine-tune specifically for your task. You're giving it the name \"Krishna_model\".\n",
    "         # Model Adapter ID: Gradient.ai assigns a unique ID to your model adapter, which you can use to access and manage it in the future.\n",
    "   \n",
    "\n",
    "   # ** 4. Test Before Fine-tuning **\n",
    "    sample_query = \"### Instruction: What is NLP and LLM? \\n\\n ### Response:\"\n",
    "    print(f\"Asking: {sample_query}\")\n",
    "    ## Before Finetuning\n",
    "    completion = new_model_adapter.complete(query=sample_query, max_generated_token_count=100).generated_output\n",
    "    print(f\"Generated(before fine tuning): {completion}\")\n",
    "       # Sample Query: You define a sample prompt asking about NLP and LLM, which you'll use to test the model's performance before and after fine-tuning.\n",
    "       # Test Completion: The new_model_adapter.complete() function sends your sample query to the model adapter and receives a generated response. This gives you a baseline to see how the model performs before training.\n",
    "    \n",
    "    \n",
    "   # ** 5. Data Preparation and Fine-tuning.** \n",
    "    samples = [\n",
    "        {\"inputs\": \"### Instruction: What is NLP? \\n\\n### Response: NLP stands for Natural Language Processing. It's a field of AI that helps computers understand and process human language.\"},\n",
    "        {\"inputs\": \"### Instruction: What is LLM? \\n\\n### Response: LLM stands for Large Language Model. It's a type of AI model trained on massive amounts of text data, allowing it to generate human-like text, translate languages, write different kinds of creative content, and answer your questions in an informative way.\"},\n",
    "        {\"inputs\": \"### Instruction: Give an example of how NLP is used. \\n\\n### Response:  One way NLP is used is in chatbots. Chatbots use NLP to understand what you're asking and give you relevant responses.\"},\n",
    "        {\"inputs\": \"### Instruction: What are some applications of LLMs? \\n\\n### Response:  LLMs have many applications, including text generation, machine translation, and question answering.\"},\n",
    "        ]\n",
    "    \n",
    "    ## Lets define parameters for finetuning\n",
    "    num_epochs=6\n",
    "    count=0\n",
    "    while count<num_epochs:\n",
    "      print(f\"Fine tuning the model with iteration {count + 1}\")\n",
    "      new_model_adapter.fine_tune(samples=samples)\n",
    "      count=count+1\n",
    "        # Sample Data: You've created a list (samples) containing several examples of \"input-response\" pairs. This is your training data. Each item in the list is a dictionary with an inputs field representing a prompt and a Response field for the desired output.\n",
    "        # *Fine-tuning with Gradient.ai* :\n",
    "                            # The new_model_adapter.fine_tune() method instructs Gradient.ai to start fine-tuning the model adapter.\n",
    "                            # samples=samples : You're passing the samples list as the training data for the fine-tuning process.\n",
    "                            # num_epochs=6 : You're training the model for 6 epochs, which means the model will see the training data 6 times during the training process. The number of epochs is a hyperparameter that you can adjust based on the size of your dataset and the complexity of the task.\n",
    "    \n",
    "    \n",
    "    # ** 6. Test After Fine-tuning **\n",
    "    completion = new_model_adapter.complete(query=sample_query, max_generated_token_count=100).generated_output\n",
    "    print(f\"Generated(after fine tuning): {completion}\")\n",
    "          # Test Again: You repeat the new_model_adapter.complete() command to see how the model's generated response has changed after fine-tuning.\n",
    "    \n",
    "    # ** 7. Cleanup **\n",
    "    new_model_adapter.delete()\n",
    "    gradient.close()\n",
    "        # Delete Model Adapter: The new_model_adapter.delete() line removes the model adapter from your Gradient.ai workspace.\n",
    "        # Close Gradient Connection: The gradient.close() line closes the connection to your Gradient.ai workspace.\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
